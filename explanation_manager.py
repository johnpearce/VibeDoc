"""
AIå¯è§£é‡Šæ€§ç®¡ç†å™¨
æä¾›å¤„ç†é“¾æ¡é€æ˜åº¦å’Œç»“åˆSOPçš„å¯è§£é‡Šæ€§åŠŸèƒ½
"""

import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
from dataclasses import dataclass, asdict
from enum import Enum

logger = logging.getLogger(__name__)

class ProcessingStage(Enum):
    """å¤„ç†é˜¶æ®µæšä¸¾"""
    INPUT_VALIDATION = "input_validation"
    PROMPT_OPTIMIZATION = "prompt_optimization"
    KNOWLEDGE_RETRIEVAL = "knowledge_retrieval"
    AI_GENERATION = "ai_generation"
    QUALITY_ASSESSMENT = "quality_assessment"
    CONTENT_FORMATTING = "content_formatting"
    RESULT_VALIDATION = "result_validation"

@dataclass
class ProcessingStep:
    """å¤„ç†æ­¥éª¤æ•°æ®ç»“æ„"""
    stage: ProcessingStage
    title: str
    description: str
    timestamp: str
    duration: float
    success: bool
    details: Dict[str, Any]
    quality_score: Optional[float] = None
    evidence: Optional[str] = None

class ExplanationManager:
    """AIå¯è§£é‡Šæ€§ç®¡ç†å™¨"""
    
    def __init__(self):
        self.processing_steps: List[ProcessingStep] = []
        self.sop_guidelines = self._load_sop_guidelines()
        self.quality_metrics = {}
        
    def start_processing(self):
        """å¼€å§‹å¤„ç†è¿‡ç¨‹"""
        self.processing_steps.clear()
        self.quality_metrics.clear()
        logger.info("ğŸ”„ å¼€å§‹å¤„ç†é“¾æ¡è¿½è¸ª")
    
    def add_processing_step(self, 
                          stage: ProcessingStage,
                          title: str,
                          description: str,
                          success: bool,
                          details: Dict[str, Any],
                          duration: float = 0.0,
                          quality_score: Optional[float] = None,
                          evidence: Optional[str] = None):
        """æ·»åŠ å¤„ç†æ­¥éª¤"""
        step = ProcessingStep(
            stage=stage,
            title=title,
            description=description,
            timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            duration=duration,
            success=success,
            details=details,
            quality_score=quality_score,
            evidence=evidence
        )
        
        self.processing_steps.append(step)
        logger.info(f"ğŸ“ è®°å½•å¤„ç†æ­¥éª¤: {title} - {'âœ…' if success else 'âŒ'}")
    
    def get_processing_explanation(self) -> str:
        """è·å–å¤„ç†è¿‡ç¨‹çš„è¯¦ç»†è¯´æ˜"""
        if not self.processing_steps:
            return "æš‚æ— å¤„ç†è®°å½•"
        
        explanation = self._generate_explanation_header()
        explanation += self._generate_sop_compliance_report()
        explanation += self._generate_processing_steps_report()
        explanation += self._generate_quality_metrics_report()
        explanation += self._generate_evidence_summary()
        
        return explanation
    
    def _generate_explanation_header(self) -> str:
        """ç”Ÿæˆè¯´æ˜å¤´éƒ¨"""
        total_steps = len(self.processing_steps)
        successful_steps = sum(1 for step in self.processing_steps if step.success)
        success_rate = (successful_steps / total_steps * 100) if total_steps > 0 else 0
        
        return f"""
# ğŸ” AIç”Ÿæˆè¿‡ç¨‹è¯¦ç»†è¯´æ˜

## ğŸ“Š å¤„ç†æ¦‚è§ˆ
- **æ€»å¤„ç†æ­¥éª¤**: {total_steps}
- **æˆåŠŸæ­¥éª¤**: {successful_steps}
- **æˆåŠŸç‡**: {success_rate:.1f}%
- **å¤„ç†æ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

---

"""
    
    def _generate_sop_compliance_report(self) -> str:
        """ç”ŸæˆSOPåˆè§„æŠ¥å‘Š"""
        return f"""
## ğŸ“‹ SOP (æ ‡å‡†æ“ä½œç¨‹åº) åˆè§„æŠ¥å‘Š

### ğŸ¯ è´¨é‡ä¿è¯æ ‡å‡†
{self._format_sop_guidelines()}

### âœ… åˆè§„æ€§æ£€æŸ¥
- **è¾“å…¥éªŒè¯**: {'âœ… é€šè¿‡' if self._check_sop_compliance('input_validation') else 'âŒ æœªé€šè¿‡'}
- **çŸ¥è¯†è·å–**: {'âœ… é€šè¿‡' if self._check_sop_compliance('knowledge_retrieval') else 'âŒ æœªé€šè¿‡'}
- **AIç”Ÿæˆ**: {'âœ… é€šè¿‡' if self._check_sop_compliance('ai_generation') else 'âŒ æœªé€šè¿‡'}
- **è´¨é‡è¯„ä¼°**: {'âœ… é€šè¿‡' if self._check_sop_compliance('quality_assessment') else 'âŒ æœªé€šè¿‡'}
- **å†…å®¹æ ¼å¼åŒ–**: {'âœ… é€šè¿‡' if self._check_sop_compliance('content_formatting') else 'âŒ æœªé€šè¿‡'}

---

"""
    
    def _generate_processing_steps_report(self) -> str:
        """ç”Ÿæˆå¤„ç†æ­¥éª¤æŠ¥å‘Š"""
        report = "## ğŸ”„ è¯¦ç»†å¤„ç†æ­¥éª¤\n\n"
        
        for i, step in enumerate(self.processing_steps, 1):
            status_icon = "âœ…" if step.success else "âŒ"
            quality_info = f" (è´¨é‡åˆ†: {step.quality_score:.1f})" if step.quality_score else ""
            
            report += f"""
### æ­¥éª¤ {i}: {step.title} {status_icon}

- **é˜¶æ®µ**: {self._get_stage_name(step.stage)}
- **æ—¶é—´**: {step.timestamp}
- **è€—æ—¶**: {step.duration:.2f}ç§’{quality_info}
- **æè¿°**: {step.description}

**è¯¦ç»†ä¿¡æ¯**:
{self._format_step_details(step.details)}

"""
            
            if step.evidence:
                report += f"**è¯æ®**: {step.evidence}\n\n"
        
        return report + "---\n\n"
    
    def _generate_quality_metrics_report(self) -> str:
        """ç”Ÿæˆè´¨é‡æŒ‡æ ‡æŠ¥å‘Š"""
        if not self.quality_metrics:
            return ""
        
        report = "## ğŸ“ˆ è´¨é‡æŒ‡æ ‡è¯¦æƒ…\n\n"
        
        for metric_name, metric_value in self.quality_metrics.items():
            report += f"- **{metric_name}**: {metric_value}\n"
        
        return report + "\n---\n\n"
    
    def _generate_evidence_summary(self) -> str:
        """ç”Ÿæˆè¯æ®æ€»ç»“"""
        evidence_steps = [step for step in self.processing_steps if step.evidence]
        
        if not evidence_steps:
            return ""
        
        report = "## ğŸ§¾ è¯æ®æ€»ç»“\n\n"
        
        for i, step in enumerate(evidence_steps, 1):
            report += f"**{i}. {step.title}**\n{step.evidence}\n\n"
        
        return report
    
    def _load_sop_guidelines(self) -> Dict[str, Any]:
        """åŠ è½½SOPæŒ‡å¯¼åŸåˆ™"""
        return {
            "input_validation": {
                "title": "è¾“å…¥éªŒè¯æ ‡å‡†",
                "requirements": [
                    "ç”¨æˆ·è¾“å…¥é•¿åº¦ >= 10å­—ç¬¦",
                    "è¾“å…¥å†…å®¹åŒ…å«äº§å“æè¿°",
                    "æ— æ¶æ„å†…å®¹å’Œæ•æ„Ÿä¿¡æ¯"
                ]
            },
            "knowledge_retrieval": {
                "title": "å¤–éƒ¨çŸ¥è¯†è·å–",
                "requirements": [
                    "MCPæœåŠ¡è¿æ¥çŠ¶æ€æ£€æŸ¥",
                    "å‚è€ƒé“¾æ¥æœ‰æ•ˆæ€§éªŒè¯",
                    "çŸ¥è¯†å†…å®¹ç›¸å…³æ€§è¯„ä¼°"
                ]
            },
            "ai_generation": {
                "title": "AIå†…å®¹ç”Ÿæˆ",
                "requirements": [
                    "ä½¿ç”¨ä¸“ä¸šçš„ç³»ç»Ÿæç¤ºè¯",
                    "ç”Ÿæˆå†…å®¹ç»“æ„å®Œæ•´",
                    "åŒ…å«å¿…è¦çš„æŠ€æœ¯ç»†èŠ‚"
                ]
            },
            "quality_assessment": {
                "title": "è´¨é‡è¯„ä¼°æ ‡å‡†",
                "requirements": [
                    "å†…å®¹å®Œæ•´æ€§æ£€æŸ¥",
                    "Mermaidå›¾è¡¨è¯­æ³•éªŒè¯",
                    "é“¾æ¥æœ‰æ•ˆæ€§æ£€æŸ¥",
                    "æ—¥æœŸå‡†ç¡®æ€§éªŒè¯"
                ]
            },
            "content_formatting": {
                "title": "å†…å®¹æ ¼å¼åŒ–",
                "requirements": [
                    "Markdownæ ¼å¼è§„èŒƒ",
                    "æ·»åŠ æ—¶é—´æˆ³å’Œå…ƒä¿¡æ¯",
                    "å¢å¼ºæç¤ºè¯æ˜¾ç¤ºæ•ˆæœ"
                ]
            }
        }
    
    def _format_sop_guidelines(self) -> str:
        """æ ¼å¼åŒ–SOPæŒ‡å¯¼åŸåˆ™"""
        formatted = ""
        for key, guideline in self.sop_guidelines.items():
            formatted += f"**{guideline['title']}**:\n"
            for requirement in guideline['requirements']:
                formatted += f"- {requirement}\n"
            formatted += "\n"
        return formatted
    
    def _check_sop_compliance(self, stage_name: str) -> bool:
        """æ£€æŸ¥SOPåˆè§„æ€§"""
        relevant_steps = [step for step in self.processing_steps 
                         if step.stage.value == stage_name]
        return len(relevant_steps) > 0 and all(step.success for step in relevant_steps)
    
    def _get_stage_name(self, stage: ProcessingStage) -> str:
        """è·å–é˜¶æ®µåç§°"""
        stage_names = {
            ProcessingStage.INPUT_VALIDATION: "è¾“å…¥éªŒè¯",
            ProcessingStage.PROMPT_OPTIMIZATION: "æç¤ºè¯ä¼˜åŒ–",
            ProcessingStage.KNOWLEDGE_RETRIEVAL: "çŸ¥è¯†è·å–",
            ProcessingStage.AI_GENERATION: "AIç”Ÿæˆ",
            ProcessingStage.QUALITY_ASSESSMENT: "è´¨é‡è¯„ä¼°",
            ProcessingStage.CONTENT_FORMATTING: "å†…å®¹æ ¼å¼åŒ–",
            ProcessingStage.RESULT_VALIDATION: "ç»“æœéªŒè¯"
        }
        return stage_names.get(stage, stage.value)
    
    def _format_step_details(self, details: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æ­¥éª¤è¯¦æƒ…"""
        formatted = ""
        for key, value in details.items():
            if isinstance(value, dict):
                formatted += f"  - **{key}**: {self._format_nested_dict(value)}\n"
            elif isinstance(value, list):
                formatted += f"  - **{key}**: {', '.join(str(item) for item in value)}\n"
            else:
                formatted += f"  - **{key}**: {value}\n"
        return formatted
    
    def _format_nested_dict(self, nested_dict: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–åµŒå¥—å­—å…¸"""
        items = []
        for key, value in nested_dict.items():
            items.append(f"{key}={value}")
        return f"{{{', '.join(items)}}}"
    
    def update_quality_metrics(self, metrics: Dict[str, Any]):
        """æ›´æ–°è´¨é‡æŒ‡æ ‡"""
        self.quality_metrics.update(metrics)
        
    def get_trust_score(self) -> float:
        """è®¡ç®—ä¿¡ä»»åˆ†æ•°"""
        if not self.processing_steps:
            return 0.0
        
        # åŸºäºæˆåŠŸç‡å’Œè´¨é‡åˆ†æ•°è®¡ç®—ä¿¡ä»»åˆ†æ•°
        success_rate = sum(1 for step in self.processing_steps if step.success) / len(self.processing_steps)
        
        quality_scores = [step.quality_score for step in self.processing_steps if step.quality_score]
        avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0.5
        
        # ä¿¡ä»»åˆ†æ•° = æˆåŠŸç‡ * 0.6 + å¹³å‡è´¨é‡åˆ†æ•° * 0.4
        trust_score = success_rate * 0.6 + (avg_quality / 100) * 0.4
        
        return round(trust_score * 100, 1)

# å…¨å±€å¯è§£é‡Šæ€§ç®¡ç†å™¨å®ä¾‹
explanation_manager = ExplanationManager()