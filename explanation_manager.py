"""
AIcan solveexplainæ€§ç®¡managedevice
æprovide process é“¾æ¡transparentdegree and ç»“åˆSOPçš„cansolveexplainæ€§åŠŸèƒ½
"""

import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
from dataclasses import dataclass, asdict
from enum import Enum

logger = logging.getLogger(__name__)

class ProcessingStage(Enum):
    """process phase æšä¸¾"""
    INPUT_VALIDATION = "input_validation"
    PROMPT_OPTIMIZATION = "prompt_optimization"
    KNOWLEDGE_RETRIEVAL = "knowledge_retrieval"
    AI_GENERATION = "ai_generation"
    QUALITY_ASSESSMENT = "quality_assessment"
    CONTENT_FORMATTING = "content_formatting"
    RESULT_VALIDATION = "result_validation"

@dataclass
class ProcessingStep:
    """process Step data ç»“construct"""
    stage: ProcessingStage
    title: str
    description: str
    timestamp: str
    duration: float
    success: bool
    details: Dict[str, Any]
    quality_score: Optional[float] = None
    evidence: Optional[str] = None

class ExplanationManager:
    """AIcan solveexplainæ€§ç®¡managedevice"""
    
    def __init__(self):
        self.processing_steps: List[ProcessingStep] = []
        self.sop_guidelines = self._load_sop_guidelines()
        self.quality_metrics = {}
        
    def start_processing(self):
        """start process procedure"""
        self.processing_steps.clear()
        self.quality_metrics.clear()
        logger.info("ğŸ”„ start process é“¾æ¡track")
    
    def add_processing_step(self, 
                          stage: ProcessingStage,
                          title: str,
                          description: str,
                          success: bool,
                          details: Dict[str, Any],
                          duration: float = 0.0,
                          quality_score: Optional[float] = None,
                          evidence: Optional[str] = None):
        """add process Step"""
        step = ProcessingStep(
            stage=stage,
            title=title,
            description=description,
            timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            duration=duration,
            success=success,
            details=details,
            quality_score=quality_score,
            evidence=evidence
        )
        
        self.processing_steps.append(step)
        logger.info(f"ğŸ“ è®°å½• process Step: {title} - {'âœ…' if success else 'âŒ'}")
    
    def get_processing_explanation(self) -> str:
        """get process procedure detailed description"""
        if not self.processing_steps:
            return "temporarilyæ—  process è®°å½•"
        
        explanation = self._generate_explanation_header()
        explanation += self._generate_sop_compliance_report()
        explanation += self._generate_processing_steps_report()
        explanation += self._generate_quality_metrics_report()
        explanation += self._generate_evidence_summary()
        
        return explanation
    
    def _generate_explanation_header(self) -> str:
        """generate description å¤´éƒ¨"""
        total_steps = len(self.processing_steps)
        successful_steps = sum(1 for step in self.processing_steps if step.success)
        success_rate = (successful_steps / total_steps * 100) if total_steps > 0 else 0
        
        return f"""
# ğŸ” AIgenerate procedure detailed description

## ğŸ“Š process generalbrowse
- **total process Step**: {total_steps}
- **success Step**: {successful_steps}
- **success ç‡**: {success_rate:.1f}%
- **process when time**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

---

"""
    
    def _generate_sop_compliance_report(self) -> str:
        """generateSOPåˆè§„æŠ¥notify"""
        return f"""
## ğŸ“‹ SOP (markå‡†operateç¨‹åº) åˆè§„æŠ¥notify

### ğŸ¯ quality ä¿è¯markå‡†
{self._format_sop_guidelines()}

### âœ… åˆè§„æ€§ check
- **input verify**: {'âœ… é€šè¿‡' if self._check_sop_compliance('input_validation') else 'âŒ not yeté€šè¿‡'}
- **knowledge acquisition**: {'âœ… é€šè¿‡' if self._check_sop_compliance('knowledge_retrieval') else 'âŒ not yeté€šè¿‡'}
- **AIgenerate**: {'âœ… é€šè¿‡' if self._check_sop_compliance('ai_generation') else 'âŒ not yeté€šè¿‡'}
- **quality assessment**: {'âœ… é€šè¿‡' if self._check_sop_compliance('quality_assessment') else 'âŒ not yeté€šè¿‡'}
- **content formatting**: {'âœ… é€šè¿‡' if self._check_sop_compliance('content_formatting') else 'âŒ not yeté€šè¿‡'}

---

"""
    
    def _generate_processing_steps_report(self) -> str:
        """generate process Step æŠ¥notify"""
        report = "## ğŸ”„ detailed process Step\n\n"
        
        for i, step in enumerate(self.processing_steps, 1):
            status_icon = "âœ…" if step.success else "âŒ"
            quality_info = f" (quality divide: {step.quality_score:.1f})" if step.quality_score else ""
            
            report += f"""
### Step {i}: {step.title} {status_icon}

- **phase**: {self._get_stage_name(step.stage)}
- **when time**: {step.timestamp}
- **consume when**: {step.duration:.2f}seconds{quality_info}
- **description**: {step.description}

**detailed information**:
{self._format_step_details(step.details)}

"""
            
            if step.evidence:
                report += f"**è¯data**: {step.evidence}\n\n"
        
        return report + "---\n\n"
    
    def _generate_quality_metrics_report(self) -> str:
        """generate quality pointmarkæŠ¥notify"""
        if not self.quality_metrics:
            return ""
        
        report = "## ğŸ“ˆ quality pointmarkè¯¦æƒ…\n\n"
        
        for metric_name, metric_value in self.quality_metrics.items():
            report += f"- **{metric_name}**: {metric_value}\n"
        
        return report + "\n---\n\n"
    
    def _generate_evidence_summary(self) -> str:
        """generate è¯data summary"""
        evidence_steps = [step for step in self.processing_steps if step.evidence]
        
        if not evidence_steps:
            return ""
        
        report = "## ğŸ§¾ è¯data summary\n\n"
        
        for i, step in enumerate(evidence_steps, 1):
            report += f"**{i}. {step.title}**\n{step.evidence}\n\n"
        
        return report
    
    def _load_sop_guidelines(self) -> Dict[str, Any]:
        """loadSOPpointguideoriginalåˆ™"""
        return {
            "input_validation": {
                "title": "input verify markå‡†",
                "requirements": [
                    "user input é•¿degree >= 10å­—symbol",
                    "input content include äº§å“ description",
                    "æ— æ¶æ„ content and æ•æ„Ÿ information"
                ]
            },
            "knowledge_retrieval": {
                "title": "å¤–éƒ¨ knowledge acquisition",
                "requirements": [
                    "MCPservice è¿connect status check",
                    "reference link have æ•ˆæ€§ verify",
                    "knowledge content ç›¸å…³æ€§ assessment"
                ]
            },
            "ai_generation": {
                "title": "AIcontent generate",
                "requirements": [
                    "use ä¸“ä¸š system prompt",
                    "generate content ç»“construct complete",
                    "include å¿… want æŠ€techniqueç»†section"
                ]
            },
            "quality_assessment": {
                "title": "quality assessment markå‡†",
                "requirements": [
                    "content complete æ€§ check",
                    "Mermaiddiagram tableè¯­æ³• verify",
                    "link have æ•ˆæ€§ check",
                    "dateå‡†ç¡®æ€§ verify"
                ]
            },
            "content_formatting": {
                "title": "content formatting",
                "requirements": [
                    "Markdownformat è§„èŒƒ",
                    "add when time æˆ³ and meta information",
                    "enhanced prompt display æ•ˆresult"
                ]
            }
        }
    
    def _format_sop_guidelines(self) -> str:
        """formattingSOPpointguideoriginalåˆ™"""
        formatted = ""
        for key, guideline in self.sop_guidelines.items():
            formatted += f"**{guideline['title']}**:\n"
            for requirement in guideline['requirements']:
                formatted += f"- {requirement}\n"
            formatted += "\n"
        return formatted
    
    def _check_sop_compliance(self, stage_name: str) -> bool:
        """checkSOPåˆè§„æ€§"""
        relevant_steps = [step for step in self.processing_steps 
                         if step.stage.value == stage_name]
        return len(relevant_steps) > 0 and all(step.success for step in relevant_steps)
    
    def _get_stage_name(self, stage: ProcessingStage) -> str:
        """get phase name called"""
        stage_names = {
            ProcessingStage.INPUT_VALIDATION: "input verify",
            ProcessingStage.PROMPT_OPTIMIZATION: "prompt optimize",
            ProcessingStage.KNOWLEDGE_RETRIEVAL: "knowledge acquisition",
            ProcessingStage.AI_GENERATION: "AIgenerate",
            ProcessingStage.QUALITY_ASSESSMENT: "quality assessment",
            ProcessingStage.CONTENT_FORMATTING: "content formatting",
            ProcessingStage.RESULT_VALIDATION: "ç»“result verify"
        }
        return stage_names.get(stage, stage.value)
    
    def _format_step_details(self, details: Dict[str, Any]) -> str:
        """formatting Step è¯¦æƒ…"""
        formatted = ""
        for key, value in details.items():
            if isinstance(value, dict):
                formatted += f"  - **{key}**: {self._format_nested_dict(value)}\n"
            elif isinstance(value, list):
                formatted += f"  - **{key}**: {', '.join(str(item) for item in value)}\n"
            else:
                formatted += f"  - **{key}**: {value}\n"
        return formatted
    
    def _format_nested_dict(self, nested_dict: Dict[str, Any]) -> str:
        """formatting åµŒå¥—å­—å…¸"""
        items = []
        for key, value in nested_dict.items():
            items.append(f"{key}={value}")
        return f"{{{', '.join(items)}}}"
    
    def update_quality_metrics(self, metrics: Dict[str, Any]):
        """update quality pointmark"""
        self.quality_metrics.update(metrics)
        
    def get_trust_score(self) -> float:
        """calculatetrustä»»divideæ•°"""
        if not self.processing_steps:
            return 0.0
        
        # åŸºäº success ç‡ and quality divideæ•°calculatetrustä»»divideæ•°
        success_rate = sum(1 for step in self.processing_steps if step.success) / len(self.processing_steps)
        
        quality_scores = [step.quality_score for step in self.processing_steps if step.quality_score]
        avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0.5
        
        # trustä»»divideæ•° = success ç‡ * 0.6 + å¹³å‡quality divideæ•° * 0.4
        trust_score = success_rate * 0.6 + (avg_quality / 100) * 0.4
        
        return round(trust_score * 100, 1)

# å…¨å±€ can solveexplainæ€§ç®¡managedevice example
explanation_manager = ExplanationManager()