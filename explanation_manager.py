"""
AIå¯è§£é‡Šæ€§ç®¡ç†å™¨
æä¾›Processé“¾æ¡é€æ˜åº¦å’Œç»“åˆSOPçš„å¯è§£é‡Šæ€§feature
"""

import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
from dataclasses import dataclass, asdict
from enum import Enum

logger = logging.getLogger(__name__)

class ProcessingStage(Enum):
    """Processé˜¶æ®µæšä¸¾"""
    INPUT_VALIDATION = "input_validation"
    PROMPT_OPTIMIZATION = "prompt_optimization"
    KNOWLEDGE_RETRIEVAL = "knowledge_retrieval"
    AI_GENERATION = "ai_generation"
    QUALITY_ASSESSMENT = "quality_assessment"
    CONTENT_FORMATTING = "content_formatting"
    RESULT_VALIDATION = "result_validation"

@dataclass
class ProcessingStep:
    """Processæ­¥éª¤dataç»“æ„"""
    stage: ProcessingStage
    title: str
    description: str
    timestamp: str
    duration: float
    success: bool
    details: Dict[str, Any]
    quality_score: Optional[float] = None
    evidence: Optional[str] = None

class ExplanationManager:
    """AIå¯è§£é‡Šæ€§ç®¡ç†å™¨"""
    
    def __init__(self):
        self.processing_steps: List[ProcessingStep] = []
        self.sop_guidelines = self._load_sop_guidelines()
        self.quality_metrics = {}
        
    def start_processing(self):
        """startProcessè¿‡ç¨‹"""
        self.processing_steps.clear()
        self.quality_metrics.clear()
        logger.info("ğŸ”„ startProcessé“¾æ¡è¿½è¸ª")
    
    def add_processing_step(self, 
                          stage: ProcessingStage,
                          title: str,
                          description: str,
                          success: bool,
                          details: Dict[str, Any],
                          duration: float = 0.0,
                          quality_score: Optional[float] = None,
                          evidence: Optional[str] = None):
        """æ·»åŠ Processæ­¥éª¤"""
        step = ProcessingStep(
            stage=stage,
            title=title,
            description=description,
            timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            duration=duration,
            success=success,
            details=details,
            quality_score=quality_score,
            evidence=evidence
        )
        
        self.processing_steps.append(step)
        logger.info(f"ğŸ“ è®°å½•Processæ­¥éª¤: {title} - {'âœ…' if success else 'âŒ'}")
    
    def get_processing_explanation(self) -> str:
        """GetProcessè¿‡ç¨‹çš„è¯¦ç»†è¯´æ˜"""
        if not self.processing_steps:
            return "æš‚æ— Processè®°å½•"
        
        explanation = self._generate_explanation_header()
        explanation += self._generate_sop_compliance_report()
        explanation += self._generate_processing_steps_report()
        explanation += self._generate_quality_metrics_report()
        explanation += self._generate_evidence_summary()
        
        return explanation
    
    def _generate_explanation_header(self) -> str:
        """Generateè¯´æ˜å¤´éƒ¨"""
        total_steps = len(self.processing_steps)
        successful_steps = sum(1 for step in self.processing_steps if step.success)
        success_rate = (successful_steps / total_steps * 100) if total_steps > 0 else 0
        
        return f"""
# ğŸ” AIGenerateè¿‡ç¨‹è¯¦ç»†è¯´æ˜

## ğŸ“Š Processæ¦‚è§ˆ
- **æ€»Processæ­¥éª¤**: {total_steps}
- **successfulæ­¥éª¤**: {successful_steps}
- **successfulç‡**: {success_rate:.1f}%
- **Processtime**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

---

"""
    
    def _generate_sop_compliance_report(self) -> str:
        """GenerateSOPåˆè§„æŠ¥å‘Š"""
        return f"""
## ğŸ“‹ SOP (æ ‡å‡†æ“ä½œç¨‹åº) åˆè§„æŠ¥å‘Š

### ğŸ¯ è´¨é‡ä¿è¯æ ‡å‡†
{self._format_sop_guidelines()}

### âœ… åˆè§„æ€§Check
- **EnterValidate**: {'âœ… é€šè¿‡' if self._check_sop_compliance('input_validation') else 'âŒ æœªé€šè¿‡'}
- **çŸ¥è¯†Get**: {'âœ… é€šè¿‡' if self._check_sop_compliance('knowledge_retrieval') else 'âŒ æœªé€šè¿‡'}
- **AIGenerate**: {'âœ… é€šè¿‡' if self._check_sop_compliance('ai_generation') else 'âŒ æœªé€šè¿‡'}
- **è´¨é‡è¯„ä¼°**: {'âœ… é€šè¿‡' if self._check_sop_compliance('quality_assessment') else 'âŒ æœªé€šè¿‡'}
- **contentformatåŒ–**: {'âœ… é€šè¿‡' if self._check_sop_compliance('content_formatting') else 'âŒ æœªé€šè¿‡'}

---

"""
    
    def _generate_processing_steps_report(self) -> str:
        """GenerateProcessæ­¥éª¤æŠ¥å‘Š"""
        report = "## ğŸ”„ è¯¦ç»†Processæ­¥éª¤\n\n"
        
        for i, step in enumerate(self.processing_steps, 1):
            status_icon = "âœ…" if step.success else "âŒ"
            quality_info = f" (è´¨é‡åˆ†: {step.quality_score:.1f})" if step.quality_score else ""
            
            report += f"""
### æ­¥éª¤ {i}: {step.title} {status_icon}

- **é˜¶æ®µ**: {self._get_stage_name(step.stage)}
- **time**: {step.timestamp}
- **è€—æ—¶**: {step.duration:.2f}s{quality_info}
- **description**: {step.description}

**è¯¦ç»†information**:
{self._format_step_details(step.details)}

"""
            
            if step.evidence:
                report += f"**è¯æ®**: {step.evidence}\n\n"
        
        return report + "---\n\n"
    
    def _generate_quality_metrics_report(self) -> str:
        """Generateè´¨é‡æŒ‡æ ‡æŠ¥å‘Š"""
        if not self.quality_metrics:
            return ""
        
        report = "## ğŸ“ˆ è´¨é‡æŒ‡æ ‡details\n\n"
        
        for metric_name, metric_value in self.quality_metrics.items():
            report += f"- **{metric_name}**: {metric_value}\n"
        
        return report + "\n---\n\n"
    
    def _generate_evidence_summary(self) -> str:
        """Generateè¯æ®æ€»ç»“"""
        evidence_steps = [step for step in self.processing_steps if step.evidence]
        
        if not evidence_steps:
            return ""
        
        report = "## ğŸ§¾ è¯æ®æ€»ç»“\n\n"
        
        for i, step in enumerate(evidence_steps, 1):
            report += f"**{i}. {step.title}**\n{step.evidence}\n\n"
        
        return report
    
    def _load_sop_guidelines(self) -> Dict[str, Any]:
        """LoadSOPæŒ‡å¯¼åŸåˆ™"""
        return {
            "input_validation": {
                "title": "EnterValidateæ ‡å‡†",
                "requirements": [
                    "userEnterlength >= 10å­—ç¬¦",
                    "EntercontentåŒ…å«äº§å“description",
                    "æ— æ¶æ„contentå’Œæ•æ„Ÿinformation"
                ]
            },
            "knowledge_retrieval": {
                "title": "å¤–éƒ¨çŸ¥è¯†Get",
                "requirements": [
                    "MCPserviceconnectionstatusCheck",
                    "å‚è€ƒlinkæœ‰æ•ˆæ€§Validate",
                    "çŸ¥è¯†contentç›¸å…³æ€§è¯„ä¼°"
                ]
            },
            "ai_generation": {
                "title": "AIcontentGenerate",
                "requirements": [
                    "ä½¿ç”¨ä¸“ä¸šçš„ç³»ç»Ÿtipè¯",
                    "Generatecontentç»“æ„å®Œæ•´",
                    "åŒ…å«å¿…è¦çš„æŠ€æœ¯ç»†èŠ‚"
                ]
            },
            "quality_assessment": {
                "title": "è´¨é‡è¯„ä¼°æ ‡å‡†",
                "requirements": [
                    "contentå®Œæ•´æ€§Check",
                    "Mermaidå›¾è¡¨è¯­æ³•Validate",
                    "linkæœ‰æ•ˆæ€§Check",
                    "æ—¥æœŸå‡†ç¡®æ€§Validate"
                ]
            },
            "content_formatting": {
                "title": "contentformatåŒ–",
                "requirements": [
                    "Markdownformatè§„èŒƒ",
                    "æ·»åŠ timeæˆ³å’Œå…ƒinformation",
                    "å¢å¼ºtipè¯Showæ•ˆæœ"
                ]
            }
        }
    
    def _format_sop_guidelines(self) -> str:
        """formatåŒ–SOPæŒ‡å¯¼åŸåˆ™"""
        formatted = ""
        for key, guideline in self.sop_guidelines.items():
            formatted += f"**{guideline['title']}**:\n"
            for requirement in guideline['requirements']:
                formatted += f"- {requirement}\n"
            formatted += "\n"
        return formatted
    
    def _check_sop_compliance(self, stage_name: str) -> bool:
        """CheckSOPåˆè§„æ€§"""
        relevant_steps = [step for step in self.processing_steps 
                         if step.stage.value == stage_name]
        return len(relevant_steps) > 0 and all(step.success for step in relevant_steps)
    
    def _get_stage_name(self, stage: ProcessingStage) -> str:
        """Geté˜¶æ®µåç§°"""
        stage_names = {
            ProcessingStage.INPUT_VALIDATION: "EnterValidate",
            ProcessingStage.PROMPT_OPTIMIZATION: "tipè¯Optimize",
            ProcessingStage.KNOWLEDGE_RETRIEVAL: "çŸ¥è¯†Get",
            ProcessingStage.AI_GENERATION: "AIGenerate",
            ProcessingStage.QUALITY_ASSESSMENT: "è´¨é‡è¯„ä¼°",
            ProcessingStage.CONTENT_FORMATTING: "contentformatåŒ–",
            ProcessingStage.RESULT_VALIDATION: "resultValidate"
        }
        return stage_names.get(stage, stage.value)
    
    def _format_step_details(self, details: Dict[str, Any]) -> str:
        """formatåŒ–æ­¥éª¤details"""
        formatted = ""
        for key, value in details.items():
            if isinstance(value, dict):
                formatted += f"  - **{key}**: {self._format_nested_dict(value)}\n"
            elif isinstance(value, list):
                formatted += f"  - **{key}**: {', '.join(str(item) for item in value)}\n"
            else:
                formatted += f"  - **{key}**: {value}\n"
        return formatted
    
    def _format_nested_dict(self, nested_dict: Dict[str, Any]) -> str:
        """formatåŒ–åµŒå¥—å­—å…¸"""
        items = []
        for key, value in nested_dict.items():
            items.append(f"{key}={value}")
        return f"{{{', '.join(items)}}}"
    
    def update_quality_metrics(self, metrics: Dict[str, Any]):
        """Updateè´¨é‡æŒ‡æ ‡"""
        self.quality_metrics.update(metrics)
        
    def get_trust_score(self) -> float:
        """è®¡ç®—ä¿¡ä»»åˆ†æ•°"""
        if not self.processing_steps:
            return 0.0
        
        # åŸºäºsuccessfulç‡å’Œè´¨é‡åˆ†æ•°è®¡ç®—ä¿¡ä»»åˆ†æ•°
        success_rate = sum(1 for step in self.processing_steps if step.success) / len(self.processing_steps)
        
        quality_scores = [step.quality_score for step in self.processing_steps if step.quality_score]
        avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0.5
        
        # ä¿¡ä»»åˆ†æ•° = successfulç‡ * 0.6 + å¹³å‡è´¨é‡åˆ†æ•° * 0.4
        trust_score = success_rate * 0.6 + (avg_quality / 100) * 0.4
        
        return round(trust_score * 100, 1)

# å…¨å±€å¯è§£é‡Šæ€§ç®¡ç†å™¨å®ä¾‹
explanation_manager = ExplanationManager()